# -*- coding: utf-8 -*-
"""SA - Predictive Analytics - Diabet (split diabet n non).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-4jp7nf0kXh7rHkq8DUAEiq8QFgy7OLb

# Proyek Pertama Machine Learning Expert Dicoding: Predictive Analytics - Diabet (split diabet n non)

- **Nama:** Sarah Adibah
- **Email:** sarahadibah06@gmail.com
- **ID Dicoding:** [addsarah](https://www.dicoding.com/users/addsarah/academies)

Submission proyek **Predictive Analytics** ini mewajibkan peserta menyelesaikan permasalahan nyata berbasis data kuantitatif dengan pendekatan **machine learning atau deep learning**, menggunakan dataset minimal **500 sampel data** yang **belum pernah digunakan sebelumnya** di kelas Dicoding atau platform lain.

Peserta harus memilih satu pendekatan dari:
- **Klasifikasi** (contoh: prediksi penyakit, churn pelanggan, klasifikasi spam)
- **Regresi** (contoh: prediksi harga rumah, estimasi pendapatan)
- **Time Series & Forecasting** (contoh: prediksi permintaan barang, ramalan cuaca)

**Ketentuan Wajib**

1. **Dataset**
   - Minimal 500 data kuantitatif.
   - Dibagi menjadi train, validation, dan test set.
   - Tidak berasal dari proyek submission Dicoding lain atau platform publikasi sebelumnya.

2. **Notebook (.ipynb)**
   - Mengandung penjelasan (text cell) pada setiap tahapan berikut:
     - **Problem Domain**
     - **Business Understanding**
     - **Data Understanding**
     - **Data Preparation**
     - **Modeling**
     - **Evaluation**
   - Menggunakan pendekatan yang sesuai dengan tipe masalah (klasifikasi/regresi/forecasting).

3. **Model**
   - Menggunakan model klasik (misal: Random Forest, XGBoost) atau deep learning (Keras, TensorFlow, PyTorch, dll).
   - Menampilkan metrik performa seperti akurasi, precision, recall, RMSE, MAE, dll.
   - Wajib menampilkan **plot evaluasi** (grafik akurasi/loss atau grafik prediksi vs aktual).

4. **File Submission**
   - File `.ipynb` telah dijalankan dan bebas error.
   - Laporan disertakan dalam bentuk `.txt` atau `.md`.
   - File tambahan seperti `.py` (jika ada).
   - Semua file dikompresi dalam satu file `.zip`.
   - File dapat diakses tanpa konfigurasi tambahan.

--------

Tips dan Saran Penilaian Tinggi

Untuk mendapatkan bintang 5, disarankan:

- Menjelaskan **tujuan bisnis/masalah riil** secara jelas.
- Melakukan **feature engineering** yang relevan dan signifikan.
- Menerapkan **callback, cross-validation**, dan **hyperparameter tuning**.
- Menyediakan **analisis error** dan diskusi mendalam terhadap hasil.
- Menyusun notebook dan laporan dengan **rapi dan komunikatif**.


**Submission akan ditolak** jika:
- Tidak dalam bentuk `.zip`.
- Tidak melampirkan laporan dalam `.md` atau `.txt`.
- Tidak menyertakan file `.ipynb` dan/atau `.py`.
- File notebook belum dijalankan.
- Rubrik penilaian wajib tidak diterapkan secara lengkap.
- File tidak bisa dibuka oleh reviewer.

# Dataset
* [Diabetes Clinical Dataset(100k rows)](https://www.kaggle.com/datasets/ziya07/diabetes-clinical-dataset100k-rows)

# Reference
* [Machine Learning Expert Modul](https://www.dicoding.com/academies/319/tutorials/17013)
* [Electric Consumption](https://github.com/aNdr3W03/Electric-Predictive-Analytics)

# **1. Library Import**

*Library* [`os`](https://docs.python.org/3/library/os.html) untuk memproses *function* dari *operating system*. `os.environ` untuk membaca *username* dan *key* [Kaggle](https://kaggle.com).

*Library* [`pandas`](https://pandas.pydata.org) untuk melakukan pemrosesan, analisis dan manipulasi data.

*Library* [`tensorflow`](https://www.tensorflow.org) untuk melakukan pelatihan *machine learning* dan *neural networks*.

*Library* [`sklearn`](https://scikit-learn.org) untuk melakukan pemrosesan *machine learning* dan *data analysis*.

*Library* [`seaborn`](https://seaborn.pydata.org) untuk membuat visualisasi data yang berbasis `matplotlib`.

*Library* [`matplotlib`](https://matplotlib.org/) untuk melakukan visualisasi menggunakan *plotting*.
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Dense

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

"""# **2. Data Loading**

## 2.1 Environment and Kaggle Credential

**Mengatur *environment*** [Colab](https://colab.research.google.com) dengan variabel `KAGGLE_USERNAME` dan variabel `KAGGLE_KEY` untuk menghubungkan platform [Kaggle](https://kaggle.com/) menggunakan [Kaggle's Beta API](https://www.kaggle.com/docs/api) Token.
"""

# Username dan key Kaggle API
os.environ['KAGGLE_USERNAME'] = 'addsarah'
os.environ['KAGGLE_KEY']      = 'eff5b83c0a0943cd628b2c66f0878a19'

"""## 2.2 Dataset Download

**Mengunduh *dataset*** dari Kaggle dengan nama *file* *dataset*, yaitu `diabetes_dataset_with_notes.csv`. *Dataset* yang digunakan dalam proyek ini adalah *dataset* [Diabetes Clinical Dataset](https://www.kaggle.com/datasets/ziya07/diabetes-clinical-dataset100k-rows) yang berupa berkas `.csv` ([Comma-separated Values](https://en.wikipedia.org/wiki/Comma-separated_values)).
"""

# Download dataset dari Kaggle
!kaggle datasets download -d ziya07/diabetes-clinical-dataset100k-rows -f diabetes_dataset_with_notes.csv

"""**Menampilkan isi *dataset*** menggunakan *library* [Pandas](https://pandas.pydata.org/) dengan mengubah format CSV menjadi *dataframe*."""

diabet = pd.read_csv('diabetes_dataset_with_notes.csv')
diabet.head()

"""## 2.3 Dataset Preparation

Menggabungkan kolom `race:AfricanAmerican`, `race:Asian`, `race:Caucasian`, `race:Hispanic`, `race:Other` menjadi satu kolom baru `race`
"""

race_columns = ['race:AfricanAmerican', 'race:Asian', 'race:Caucasian', 'race:Hispanic', 'race:Other']
diabet['race'] = diabet[race_columns].idxmax(axis=1)

diabet['race'] = diabet['race'].str.replace('race:', '')

diabet.drop(columns=race_columns, inplace=True)

"""Menghapus kolom yang tidak akan digunakan yaitu, kolom `clinical_notes`."""

diabet.drop('clinical_notes', inplace=True, axis=1)

"""# **3. Data Understanding**

## 3.1 Menampilkan Data pada Dataframe `diabet`
"""

diabet.head()

"""## 3.2 *Exploratory Data Analysis* (EDA)

*Explanatory Data Analysis* (EDA) adalah suatu proses investigasi awal pada data untuk melakukan analisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data dengan menggunakan bantuan statistik dan representasi grafis atau visualisasi.

### 3.2.1 Deskripsi Variabel

Melakukan pengecekan informasi dari *dataframe* `diabet` seperti, jumlah kolom, nama kolom, jumlah data setiap kolom, dan tipe data pada kolom.
"""

diabet.info()

"""Terdapat tiga (3) atribut dengan tipe data `float64` dan lima (5) atribut dengan tipe data `int64`. Selain itu, terdapat empat (4) atribut dengan tipe data `object` yang merepresentasikan data kategorikal seperti `gender`, `location`, `smooking_history`, dan `race`.

### 3.2.2 Deskripsi Statistik
"""

diabet.describe()

"""Melihat deskripsi statistik dari *dataframe* `diabet` yaitu,
1.   `count` : Jumlah data
2.   `mean` : Rata-rata
3.   `std` : Standar deviasi/simpangan baku
4.   `min` : Nilai minimum
5.   `25%` : Kuartil bawah/Q1
6.   `50%` : Kuartil tengah/Q2/median
7.   `75%` : Kuartil atas/Q3
8.   `max` : Nilai maksimum

### 3.2.3 Menangani *Missing Value*

Melakukan pengecekan apakah pada *dataframe* `diabet` terdapat nilai yang *null*/kosong.
"""

diabet.isnull().sum()

"""Pada *dataframe* `diabet` ternyata tidak ditemukan adanya nilai *null*/kosong di setiap atribut/kolom.

### 3.2.4 Menangani *Outliers*

Memisahkan data pasien dengan label diabetes dan non diabetes
"""

df_diabetes = diabet[diabet['diabetes'] == 1]
df_ndiabetes = diabet[diabet['diabetes'] == 0]

diabet.diabetes.value_counts()

"""Melakukan pengecekan pada *dataframe* `diabet` label `diabet` dan label `non diabet` terdapat data *outliers* atau sampel data yang nilainya berada sangat jauh dari cakupan umum data utama yang dapat merusak hasil analisis data. Pengecekan dilakukan dengan cara visualisasi data menggunakan [`boxplot`](https://seaborn.pydata.org/generated/seaborn.boxplot.html) dengan bantuan *library* [`seaborn`](https://seaborn.pydata.org/).:"""

fig, axes = plt.subplots(2, 4, figsize=(14, 7))
sns.boxplot(ax=axes[0, 0], x=df_diabetes.year)
sns.boxplot(ax=axes[0, 1], x=df_diabetes.age)
sns.boxplot(ax=axes[0, 2], x=df_diabetes.hypertension)
sns.boxplot(ax=axes[0, 3], x=df_diabetes.heart_disease)

sns.boxplot(ax=axes[1, 0], x=df_diabetes.bmi)
sns.boxplot(ax=axes[1, 1], x=df_diabetes.hbA1c_level)
sns.boxplot(ax=axes[1, 2], x=df_diabetes.blood_glucose_level)
sns.boxplot(ax=axes[1, 3], x=df_diabetes.diabetes)

fig, axes = plt.subplots(2, 4, figsize=(14, 7))
sns.boxplot(ax=axes[0, 0], x=df_ndiabetes.year)
sns.boxplot(ax=axes[0, 1], x=df_ndiabetes.age)
sns.boxplot(ax=axes[0, 2], x=df_ndiabetes.hypertension)
sns.boxplot(ax=axes[0, 3], x=df_ndiabetes.heart_disease)

sns.boxplot(ax=axes[1, 0], x=df_ndiabetes.bmi)
sns.boxplot(ax=axes[1, 1], x=df_ndiabetes.hbA1c_level)
sns.boxplot(ax=axes[1, 2], x=df_ndiabetes.blood_glucose_level)
sns.boxplot(ax=axes[1, 3], x=df_ndiabetes.diabetes)

"""Dapat dilihat pada diagram boxplot (diagram kotak garis) di atas, terdapat beberapa fitur numerik yang memiliki *outliers* seperti, `Year`, `Age`, `Hypertension`, `heart_disease` dan `bmi`.

Untuk mengatasi *outliers*, dilakukan pendekatan menggunakan metode IQR (*Inter Quartile Range*).  

$IQR=Q3-Q1$  

Kemudian membuat batas bawah dan batas atas untuk mencakupi *outliers*.  

$batasBawah=Q1-1.5*IQR$  
$batasAtas=Q3-1.5*IQR$
"""

# Hitung Q1, Q3, dan IQR hanya untuk kolom numerikal
# Define numeric_cols to include all numerical features in your dataset
numeric_cols = ['year', 'hypertension', 'heart_disease', 'bmi', 'hbA1c_level', 'blood_glucose_level', 'diabetes']
Q1 = df_diabetes[numeric_cols].quantile(0.25)
Q3 = df_diabetes[numeric_cols].quantile(0.75)
IQR = Q3 - Q1

# Buat filter untuk menghapus baris yang mengandung outlier di kolom numerikal
filter_outliers = ~((df_diabetes[numeric_cols] < (Q1 - 1.5 * IQR)) |
                    (df_diabetes[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)

# Terapkan filter ke dataset asli (termasuk kolom non-numerikal)
df_diabetes = df_diabetes[filter_outliers]
# Cek ukuran dataset setelah outlier dihapus
df_diabetes.shape

# Hitung Q1, Q3, dan IQR hanya untuk kolom numerikal
# Define numeric_cols to include all numerical features in your dataset
numeric_cols = ['year', 'hypertension', 'heart_disease', 'bmi', 'hbA1c_level', 'blood_glucose_level', 'diabetes']
Q1 = df_ndiabetes[numeric_cols].quantile(0.25)
Q3 = df_ndiabetes[numeric_cols].quantile(0.75)
IQR = Q3 - Q1

# Buat filter untuk menghapus baris yang mengandung outlier di kolom numerikal
filter_outliers = ~((df_ndiabetes[numeric_cols] < (Q1 - 1.5 * IQR)) |
                    (df_ndiabetes[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)

# Terapkan filter ke dataset asli (termasuk kolom non-numerikal)
df_ndiabetes = df_ndiabetes[filter_outliers]
# Cek ukuran dataset setelah outlier dihapus
df_ndiabetes.shape

"""Sehingga diperoleh data yang telah dibersihkan sebanyak 4197 untuk diabetes sampel dan 62314 untuk non diabetes sampel.

Melakukan pengecekan kembali terhadap *outliers* dengan menggunakan visualisasi boxplot.
"""

fig, axes = plt.subplots(2, 4, figsize=(14, 7))
sns.boxplot(ax=axes[0, 0], x=df_diabetes.year)
sns.boxplot(ax=axes[0, 1], x=df_diabetes.age)
sns.boxplot(ax=axes[0, 2], x=df_diabetes.hypertension)
sns.boxplot(ax=axes[0, 3], x=df_diabetes.heart_disease)

sns.boxplot(ax=axes[1, 0], x=df_diabetes.bmi)
sns.boxplot(ax=axes[1, 1], x=df_diabetes.hbA1c_level)
sns.boxplot(ax=axes[1, 2], x=df_diabetes.blood_glucose_level)
sns.boxplot(ax=axes[1, 3], x=df_diabetes.diabetes)

fig, axes = plt.subplots(2, 4, figsize=(14, 7))
sns.boxplot(ax=axes[0, 0], x=df_ndiabetes.year)
sns.boxplot(ax=axes[0, 1], x=df_ndiabetes.age)
sns.boxplot(ax=axes[0, 2], x=df_ndiabetes.hypertension)
sns.boxplot(ax=axes[0, 3], x=df_ndiabetes.heart_disease)

sns.boxplot(ax=axes[1, 0], x=df_ndiabetes.bmi)
sns.boxplot(ax=axes[1, 1], x=df_ndiabetes.hbA1c_level)
sns.boxplot(ax=axes[1, 2], x=df_ndiabetes.blood_glucose_level)
sns.boxplot(ax=axes[1, 3], x=df_ndiabetes.diabetes)

"""Setelah dilakukan pembersihan *outliers* menggunakan metode IQR (*Inter Quartile Range*), dapat dilihat bahwa *outliers* telah berkurang pada boxplot di atas. Meskipun *outliers* masih ada pada fitur `age` dan`bmi`, tetapi masih dalam batas aman.

Menggabungkan data diabetes dan non diabetes
"""

df_diabet = pd.concat([df_diabetes, df_ndiabetes])

"""### 3.2.5 Univariate Analysis

Melakukan proses analisis data *univariate* pada fitur-fitur numerik.
"""

categorical_features = ['gender', 'location', 'smoking_history', 'race']

feature = categorical_features[0]

count = df_diabet[feature].value_counts()
percent = 100 * df_diabet[feature].value_counts(normalize=True)

df = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})
print(df)

count.plot(kind='bar', title=feature)
plt.ylabel('Jumlah')
plt.xlabel(feature)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Mayoritas pasien berjenis kelamin perempuan (58.7%), diikuti oleh laki-laki (41.3%), dan hanya 0.0% atau 16 orang yang dikategorikan sebagai Other"""

feature = categorical_features[1]

count = df_diabet[feature].value_counts()
percent = 100 * df_diabet[feature].value_counts(normalize=True)

df = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})
print(df)

count.plot(kind='bar', title=feature)
plt.ylabel('Jumlah')
plt.xlabel(feature)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Distribusi pasien tersebar cukup merata di seluruh negara bagian AS. Lokasi dengan jumlah pasien tertinggi antara lain Nebraska, New Jersey, dan North Dakota, masing-masing menyumbang sekitar 2.1% dari total data. Sementara itu, lokasi dengan jumlah pasien paling sedikit adalah Wisconsin (hanya 2 sampel atau 0.0%) dan Virgin Islands (0.9%). Hal ini menunjukkan bahwa sebagian besar data berasal dari wilayah yang beragam, namun terdapat perbedaan jumlah sampel yang signifikan antar lokasi."""

feature = categorical_features[2]

count = df_diabet[feature].value_counts()
percent = 100 * df_diabet[feature].value_counts(normalize=True)

df = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})
print(df)

count.plot(kind='bar', title=feature)
plt.ylabel('Jumlah')
plt.xlabel(feature)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Mayoritas data tidak memiliki informasi riwayat merokok (No Info) sebanyak 38.2%, diikuti oleh pasien yang tidak pernah merokok (never) sebesar 34.5%. Sementara itu, kategori lainnya seperti current (masih merokok), former (mantan perokok), not current, dan ever (pernah merokok) memiliki proporsi yang jauh lebih kecil, masing-masing kurang dari 10%. Hal ini menunjukkan bahwa lebih dari setengah data berasal dari pasien yang tidak pernah merokok atau tidak memiliki informasi lengkap terkait kebiasaan merokok."""

feature = categorical_features[3]

count = df_diabet[feature].value_counts()
percent = 100 * df_diabet[feature].value_counts(normalize=True)

df = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})
print(df)

count.plot(kind='bar', title=feature)
plt.ylabel('Jumlah')
plt.xlabel(feature)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Setiap kategori ras seperti AfricanAmerican, Caucasian, Hispanic, Asian, dan Other memiliki jumlah sampel yang hampir sama, dengan masing-masing berkisar 19.8% hingga 20.1%. Hal ini menunjukkan bahwa data telah dikonstruksi secara proporsional antar kelompok ras, sehingga tidak terjadi ketimpangan distribusi yang dapat memengaruhi performa model secara bias terhadap kelompok tertentu."""

df_diabet.hist(bins=50, figsize=(14, 12))
plt.show()

"""Dari data histogram di atas diperoleh informasi, yaitu:
1. `year` menunjukkan seluruh data diambil mayoritas pada tahun 2019.
2. `age` memiliki distribusi yang relatif merata dari usia muda hingga tua, tetapi terdapat lonjakan signifikan pada usia sekitar 80 tahun, menandakan banyaknya pasien berusia lanjut.
3. `hypertension` didominasi oleh nilai 0, yang berarti sebagian besar pasien tidak memiliki riwayat hipertensi.
4. `heart_disease` juga sangat didominasi oleh nilai 0, menunjukkan bahwa sebagian besar pasien tidak memiliki riwayat penyakit jantung.
5. `bmi` memiliki distribusi yang mendekati normal, namun terdapat lonjakan tinggi di satu nilai (sekitar 28–30).
6. `hbA1c_level` memiliki persebaran data yang beragam, tetapi paling sering berada pada level 6, yang merupakan batas prediabetes.
7. `blood_glucose_level` menunjukkan beberapa lonjakan pada nilai tertentu (sekitar 100–150), menunjukkan data tidak tersebar merata dan cenderung dikelompokkan.
8. `diabetes` sangat tidak seimbang, dimana mayoritas data menunjukkan pasien tidak menderita diabetes (nilai 0), dan hanya sebagian kecil yang menderita diabetes (nilai 1).

### 3.2.6 Multivariate Analysis

Melakukan visualisasi distribusi data pada fitur-fitur numerik dari *dataframe* `diabet`. Visualisasi dilakukan dengan bantuan *library* `seaborn` `pairplot` menggunakan parameter `diag_kind`, yaitu `kde`, untuk melihat perkiraan distribusi probabilitas antar fitur numerik.
"""

sns.pairplot(df_diabet, diag_kind='kde')

"""### 3.2.7 Correlation Matrix menggunakan *Heatmap*

Melakukan pengecekan korelasi antar fitur numerik dengan menggunakan visualisasi diagram *heatmap* *correlation matrix*.
"""

plt.figure(figsize = (10, 8))
numerical_features = ['year', 'age', 'hypertension', 'heart_disease', 'bmi', 'hbA1c_level', 'blood_glucose_level', 'diabetes']
correlation_matrix = df_diabet[numerical_features].corr().round(2)

sns.heatmap(
    data       = correlation_matrix,
    vmin       = -1,
    vmax       = 1,
    cmap       = 'coolwarm',
    annot      = True,
    linewidths = 0.5
)

plt.title('Correlation Matrix untuk Fitur Numerik', size=20)

"""Dapat dilihat pada diagram *heatmap* di atas memiliki *range* atau rentang angka dari 1.0 hingga 0.08 dengan keterangan sebagai berikut,
*   Jika semakin mendekati 1, maka korelasi antar fitur numerik semakin kuat bernilai positif.
*   Jika semakin mendekati 0, maka korelasi antar fitur numerik semakin rendah.
*   Jika semakin mendekati -1, maka korelasi antar fitur numerik semakin kuat bernilai negatif.

Jika korelasi bernilai positif, berarti nilai kedua fitur numerik cenderung meningkat bersama-sama.

Jika korelasi bernilai negatif, berarti nilai salah satu fitur numerik cenderung meningkat ketika nilai fitur numerik yang lain menurun.

# **4. Data Preparation**

## 4.1 Split Data

Mengubah fitur kategorikal menjadi numerik menggunakan Label Encoding agar semua data dalam dataset bertipe numerik
"""

categorical_features = ['gender', 'location', 'smoking_history', 'race']

# Create a LabelEncoder object
le = LabelEncoder()

# Iterate through each categorical feature
for feature in categorical_features:
  # Fit and transform the feature using LabelEncoder
  df_diabet[feature] = le.fit_transform(df_diabet[feature])

# Display the first few rows of the dataframe with numerical categorical features
df_diabet.head()

"""Melakukan *define* atau mendefinisikan variabel `x` yang berisi fitur-fitur untuk memprediksi diabetes dengan mengecualikan fitur yang tidak diperlukan, serta variabel `y` yang merupakan fitur target atau nilai yang akan diprediksi."""

x = df_diabet[['age', 'bmi', 'hbA1c_level', 'blood_glucose_level', 'gender', 'location', 'smoking_history', 'race']] # Include the numerical features
y = df_diabet['diabetes']

"""Melakukan pembagian *dataset* (*split data*) dengan menggunakan `train_test_split` menjadi data latih (*training*) dan data uji (*testing*). Lalu menampilkan total *dataset* secara keseluruhan, total data latih (*training*), dan total data uji (*testing*)."""

xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.1, random_state=123)

print(f'Total seluruh sampel : {len(x)}')
print(f'Total data train     : {len(xTrain)}')
print(f'Total data test      : {len(xTest)}')

"""## 4.2 Standarisasi pada Fitur Numerik

Melakukan standarisasi nilai pada fitur numerik dengan menggunakan `StandardScaler` dari *library* `scikit-learn`. Proses standarisasi ini bertujuan untuk mencegah terjadinya penyimpangan nilai data yang cukup besar.
"""

numericalFeatures = ['age', 'bmi', 'hbA1c_level', 'blood_glucose_level'] # Exclude 'diabetes' as it's the target variable

scaler = StandardScaler()
scaler.fit(xTrain[numericalFeatures])
xTrain[numericalFeatures] = scaler.transform(xTrain.loc[:, numericalFeatures])
xTrain[numericalFeatures].head()

xTrain[numericalFeatures].describe().round(4)

"""`StandardScaler` akan melakukan proses standarisasi fitur dengan mengurangkan nilai rata-rata (`mean`) lalu membaginya dengan standar deviasi/simpangan baku (`std`) untuk menggeser distribusi nilai. Proses standarisasi akan menghasilakn distribusi dengan nilai rata-rata (`mean`) menjadi 0 dan nilai standar deviasi/simpangan baku (`std`) menjadi 1.

# **5. Model Development**

## 5.1 *Model Preparation*

Mempersiapkan *dataframe* untuk melakukan analisis model dengan parameter `index`, yaitu `train_mse` dan `test_mse`, serta parameter `columns` yang merupakan algoritma yang akan digunakan untuk melakukan prediksi, yaitu algoritma K-Nearest Neighbor (KNN), Random Forest, dan Adaptive Boosting (AdaBoost).
"""

models = pd.DataFrame(
    index   = ['train_mse', 'test_mse'],
    columns = ['KNN', 'RandomForest', 'Boosting']
)

"""## 5.2 K-Nearest Neighbor (KNN) Algorithm

Algoritma K-Nearest Neighbor (KNN) akan menggunakan metode kemiripan dari data uji (*testing*) dan data latih (*training*) dengan mencari kesamaan pada fitur-fiturnya. K-Nearest Neighbor bekerja dengan membandingkan jarak satu sampel ke sampel pelatihan lain berdasarkan sejumlah k-tetangga terdekat (k = nilai atau angka positif).
"""

knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(xTrain, yTrain)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(xTrain), y_true=yTrain)

"""## 5.3 Random Forest Algorithm

Algoritma Random Forest merupakan algoritma *supervised learning* yang termasuk pada golongan *ensemble* (*group*) *learning*. Oleh karena itu, algoritma Random Forest terdiri dari beberapa model yang akan bekerja bersama-sama secara independen, dan prediksi dari setiap model ensemble akan digabungkan untuk membuat hasil prediksi akhir.
"""

rf = RandomForestClassifier(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
rf.fit(xTrain, yTrain)

models.loc['train_mse', 'RandomForest'] = mean_squared_error(y_pred=rf.predict(xTrain), y_true=yTrain)

"""## 5.4 Adaptive Boosting (AdaBoost) Algorithm

Algoritma Adaptive Boosting (AdaBoost) merupakan algoritma yang melatih model secara berurutan dan dalam proses iteratif (berulang). Data latih (training) akan memiliki *weight* atau bobot yang sama, kemudian model akan melakukan pemeriksaan atau observasi. Bobot yang lebih tinggi kemudian akan dimasukkan ke dalam model yang salah sehingga akan lanjut ke tahap selanjutnya. Proses iteratif tersebut akan berlanjut hingga model mencapai akurasi yang diinginkan.
"""

boosting = AdaBoostClassifier(learning_rate=0.05, random_state=55)
boosting.fit(xTrain, yTrain)

models.loc['train_mse', 'Boosting'] = mean_squared_error(y_pred=boosting.predict(xTrain), y_true = yTrain)

"""# **6. *Model Evaluation***

Melakukan standarisasi atau *scaling* pada fitur numerik data uji (*testing*) sehingga rata-rata (*mean*) bernilai 0, dan varians bernilai 1.
"""

xTest.loc[:, numericalFeatures] = scaler.transform(xTest[numericalFeatures])

"""Melakukan evaluasi dari ketiga model, yaitu algoritma K-Nearest Neighbor, Random Forest, dan Adaptive Boosting (AdaBoost) untuk masing-masing data latih (*training*) dan data uji (*testing*) dengan melihat tingkat *error*-nya menggunakan Mean Squared Error (MSE)."""

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN', 'RF', 'Boosting'])

modelDict = {
    'KNN'     : knn,
    'RF'      : rf,
    'Boosting': boosting
}

for name, model in modelDict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=yTrain, y_pred=model.predict(xTrain))/1e3
    mse.loc[name, 'test']  = mean_squared_error(y_true=yTest,  y_pred=model.predict(xTest))/1e3

mse

"""Melakukan visualisasi data *error* setiap model dengan algoritma K-Nearest Neighbor, Random Forest, dan Adaptive Boosting (AdaBoost) untuk masing-masing data latih (*training*) dan data uji (*testing*) dengan menggunakan plot *bar chart*."""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Dari visualisasi diagram di atas dapat disimpulkan bahwa,
1. Model dengan algoritma Random Forest memberikan nilai error yang paling kecil, yaitu sebesar 0.000016 pada training error, dan 0.000016 pada testing error. Ini menunjukkan bahwa model mampu melakukan prediksi dengan baik dan memiliki generalisasi yang kuat.

2. Model dengan algoritma K-Nearest Neighbor memiliki tingkat error yang sedang di antara dua algoritma lainnya, dengan nilai training error sebesar 0.000035, dan testing error sebesar 0.000034. Meskipun selisih error kecil, performa Boosting masih berada di bawah Random Forest dalam hal akurasi prediksi keseluruhan.

3. Model dengan algoritma Adaptive Boosting mengalami error yang lebih besar dibandingkan Random Forest dan K-Nearest Neighbor, dengan nilai training error sebesar 0.000053, dan testing error sebesar 0.000048.

Melakukan pengujian prediksi dengan menggunakan beberapa nilai diabetes `df_diabet` dari data uji (*testing*)
"""

prediksi  = xTest.iloc[:1].copy()
pred_dict = {'y_true': yTest[:1]}

for name, model in modelDict.items():
    pred_dict['prediksi_' + name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Dapat dilihat bahwa prediksi pada model dengan algoritma **Random Forest** memberikan hasil yang **paling mendekati nilai `y_true`** jika dibandingkan dengan model algoritma lainnya.

Nilai `y_true` adalah **0**, yang berarti pasien tersebut **tidak menderita diabetes**, dan ketiga model (`KNN`, `Random Forest`, dan `Boosting`) sama-sama menghasilkan prediksi sebesar **0.0** yang menunjukkan bahwa model memperkirakan pasien tidak mengidap diabetes.

Meskipun dalam kasus ini seluruh model memberikan hasil prediksi yang identik dengan nilai sebenarnya, model **Random Forest** tetap dianggap sebagai model dengan **tingkat *error* paling rendah secara keseluruhan**, berdasarkan evaluasi sebelumnya pada metrik MSE (*Mean Squared Error*).

Kesimpulannya adalah model yang digunakan untuk melakukan prediksi **diabetes (binary classification)** memberikan hasil terbaik ketika menggunakan algoritma **Random Forest**, karena mampu menghasilkan prediksi yang akurat dan konsisten dengan nilai `y_true`.
"""